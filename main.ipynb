{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following are analysis performed for this Bachelor Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import header as head\n",
    "import json\n",
    "import os\n",
    "\n",
    "annotations_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/annotations\"\n",
    "community_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection\"\n",
    "bridges_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 74 rumour source tweet with 0 non-rumour source tweet within the total of 74 rumour tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = head.getPath()\n",
    "# print(p)\n",
    "head.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging following relationship into a JSON file\n",
    "head.followRelate()\n",
    "\n",
    "with open('/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/relateIds.json') as f:\n",
    "    data = json.load(f)\n",
    "    followRelate_Ids = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dictionary for tweetId and userId conversion\n",
    "# results are saved in Id-conversions folder\n",
    "head.gen_idConversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are followers who reacted to the source tweets. \n",
    "* reacts from followers are saved in `react_follows`\n",
    "* reacts from non-followers are saved in `react_not_follows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See whether there are any reactors that follows the person they responded to \n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/relateIds.json\") as f:\n",
    "    followingRelate = json.load(f)\n",
    "\n",
    "head.is_follower_react(followingRelate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bridge has followers from both communities\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as f:\n",
    "    user_followed_by = json.load(f)\n",
    "\n",
    "two_com_bridges = {}\n",
    "for id in user_followed_by:\n",
    "   user = user_followed_by[id]\n",
    "   if len(user[\"rumours\"]) > 0 and len(user[\"non_rumours\"]) > 0:\n",
    "       two_com_bridges[id] = user_followed_by[id]\n",
    "\n",
    "head.writeToJSON(bridges_path,\"both_communities\",two_com_bridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bridge only has followers from one community but follows other community \n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as f:\n",
    "    follows = json.load(f)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as f:\n",
    "    user_followed_by = json.load(f)\n",
    "\n",
    "one_com_bridges = {}\n",
    "popList = []\n",
    "\n",
    "for id in user_followed_by:\n",
    "    user = user_followed_by[id]\n",
    "    if len(user[\"rumours\"]) == 0 or len(user[\"non_rumours\"]) == 0:\n",
    "        if len(user[\"rumours\"]) == 0 and len(user[\"non_rumours\"]) == 0:\n",
    "            continue\n",
    "        \n",
    "        else : one_com_bridges[id] = user_followed_by[id]\n",
    "\n",
    "for b in one_com_bridges:\n",
    "    fans = one_com_bridges[b]\n",
    "    fans[\"follow\"]=[]\n",
    "    try: followList = follows[b]\n",
    "    except: continue\n",
    "\n",
    "    if len(fans[\"rumours\"]) == 0:\n",
    "        for f in followList:\n",
    "            if f in rumours_set: fans[\"follow\"].append(f)\n",
    "    else:\n",
    "        for f in followList:\n",
    "            if f in non_rumours_set: fans[\"follow\"].append(f)\n",
    "\n",
    "    if (len(fans[\"follow\"])==0): popList.append(b)\n",
    "\n",
    "for p in popList:\n",
    "    one_com_bridges.pop(p)\n",
    "\n",
    "head.writeToJSON(bridges_path,\"single_community2\",one_com_bridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bridge only has followers from one community but follows other bridges\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as f:\n",
    "    followers = json.load(f)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as f:\n",
    "    follows = json.load(f)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/both_communities.json\") as f:\n",
    "    bi_commun_bridges = json.load(f)\n",
    "    bi_commun_bridges = list(bi_commun_bridges.keys())\n",
    "\n",
    "one_com_bridges = {}\n",
    "for id in followers:\n",
    "    user = followers[id]\n",
    "    if len(user[\"rumours\"]) == 0 or len(user[\"non_rumours\"]) == 0:\n",
    "        if len(user[\"rumours\"]) == 0 and len(user[\"non_rumours\"]) == 0:\n",
    "            continue\n",
    "        \n",
    "        else : one_com_bridges[id] = followers[id]\n",
    "\n",
    "for b in list(one_com_bridges):\n",
    "    fans = one_com_bridges[b]\n",
    "    fans[\"followed_bridges\"]=[]\n",
    "    try: followList = follows[b]\n",
    "    except: continue\n",
    "\n",
    "    for f in followList:\n",
    "        if f in bi_commun_bridges : fans[\"followed_bridges\"].append(f)\n",
    "        if f in fans[\"rumours\"] : fans[\"rumours\"].remove(f)\n",
    "        if f in fans[\"non_rumours\"] : fans[\"non_rumours\"].remove(f)\n",
    "\n",
    "    if len(fans[\"followed_bridges\"])==0: one_com_bridges.pop(b)\n",
    "\n",
    "head.writeToJSON(bridges_path,\"follows_bridges\",one_com_bridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  filter out the bridges ids from following list\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as f:\n",
    "    following_relate = json.load(f)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/both_communities.json\") as f:\n",
    "    bi_commun_bridges = json.load(f)\n",
    "    bi_commun_bridges = list(bi_commun_bridges.keys())\n",
    "\n",
    "new_follow = {}\n",
    "\n",
    "for id in following_relate:\n",
    "    user = following_relate[id]\n",
    "    new_follow[id] = {\n",
    "        \"rumours\":[],\n",
    "        \"non_rumours\":[],\n",
    "        \"bridges\":[]\n",
    "    }\n",
    "\n",
    "    rumours = (new_follow[id])[\"rumours\"]\n",
    "    non_rumours = (new_follow[id])[\"non_rumours\"]\n",
    "    bridges = (new_follow[id])[\"bridges\"]\n",
    "    \n",
    "    \n",
    "    for r in user[\"rumours\"]:\n",
    "        if r in bi_commun_bridges: \n",
    "            bridges.append(r)\n",
    "        else:\n",
    "            rumours.append(r)\n",
    "    \n",
    "    for r in user[\"non_rumours\"]:\n",
    "        if r in bi_commun_bridges: \n",
    "            bridges.append(r)\n",
    "        else:\n",
    "            non_rumours.append(r)\n",
    "\n",
    "head.writeToJSON(bridges_path,\"followers\",new_follow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/both_communities.json\") as f:\n",
    "    bi_commun_bridges = json.load(f)\n",
    "    bi_commun_bridges = list(bi_commun_bridges.keys())\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/communities.json\") as f:\n",
    "    communities = json.load(f)\n",
    "\n",
    "communities[\"bridges\"] = []\n",
    "\n",
    "for id in communities[\"rumours\"]:\n",
    "    if (id == \"428333\") : print(id)\n",
    "    if id in bi_commun_bridges : \n",
    "        (communities[\"rumours\"]).remove(id)\n",
    "        (communities[\"bridges\"]).append(id)\n",
    "\n",
    "for id in communities[\"non_rumours\"]:\n",
    "    if id in bi_commun_bridges : \n",
    "        (communities[\"non_rumours\"]).remove(id)\n",
    "        (communities[\"bridges\"]).append(id)\n",
    "\n",
    "# head.writeToJSON(community_path,\"with_bridges3\",communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bridge Analysis**\n",
    "- Type 1: Bridges that have followers from both communities\n",
    "  -  Betweeness Centrality : \n",
    "  \n",
    "- Type 2: Bridges that have followers only from one communities, and follow one or more bridges itself. \n",
    "  -  Betweeness Centrality : How critical is the node in spreading information into the community where all its followers are from.\n",
    "  -  Closeness Centrality : How efficient it is for information to spread from this user/node.\n",
    "\n",
    "**Community Analysis**\n",
    "- Closeness Centrality : lower the closeness indicates the more important the node is within its echo chamber. \n",
    "-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
