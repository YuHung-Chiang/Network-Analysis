{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bridge Analysis**\n",
    "- Type 1: Bridges that have followers from both communities\n",
    "  -  Betweeness Centrality :   \n",
    "\n",
    "- Type 2: Bridges that have followers only from one communities, and follow one or more bridges itself.\n",
    "  -  Betweeness Centrality : How critical is the node in spreading information into the community where all its followers are from.\n",
    "  -  Closeness Centrality : How efficient it is for information to spread from this user/node.\n",
    "\n",
    "**Community Analysis**\n",
    "- Closeness Centrality : lower the closeness indicates the more important the node is within its echo chamber. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, '/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset')\n",
    "import header as head\n",
    "import centrality_head as ch\n",
    "\n",
    "centrality_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge Represent following relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(communities[\"rumours\"])\n",
    "rumourEdges = []\n",
    "rumourNodes = communities[\"rumours\"]\n",
    "\n",
    "G.add_nodes_from(communities[\"non_rumours\"])\n",
    "non_rumourEdges = []\n",
    "non_rumourNodes = communities[\"non_rumours\"]\n",
    "\n",
    "G.add_nodes_from(communities[\"bridges\"])\n",
    "bridgeEdges = []\n",
    "bridgeNodes = communities[\"bridges\"]\n",
    "\n",
    "for id in followed_by:\n",
    "    user = followed_by[id]\n",
    "\n",
    "    # if id in communities[\"rumours\"]: rumourNodes.append(id)\n",
    "    # elif id in communities[\"non_rumours\"]: non_rumourNodes.append(id)\n",
    "    # elif id in communities[\"bridges\"]: bridgeNodes.append(id)\n",
    "\n",
    "    for follower in user[\"rumours\"]: \n",
    "        rumourEdges.append((follower,id))\n",
    "        G.add_edge(follower,id)\n",
    "\n",
    "    for follower in user[\"non_rumours\"]: \n",
    "        non_rumourEdges.append((follower,id))\n",
    "        G.add_edge(follower,id)\n",
    "    \n",
    "    for follower in user[\"bridges\"]: \n",
    "        bridgeEdges.append((follower,id))\n",
    "        G.add_edge(follower,id)\n",
    "\n",
    "isolates = list(nx.isolates(G))\n",
    "G.remove_edges_from(isolates)\n",
    "\n",
    "isolates = set(isolates)\n",
    "rumourNodes = set(rumourNodes).difference(isolates)\n",
    "non_rumourNodes = set(non_rumourNodes).difference(isolates)\n",
    "bridgeNodes = set(bridgeNodes).difference(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414653470\n",
      "2842650084\n",
      "21886391\n",
      "886911072\n",
      "701094366\n",
      "742143\n",
      "505322398\n",
      "538601381\n",
      "70119298\n",
      "324908191\n",
      "237617005\n",
      "2230258634\n",
      "262345797\n",
      "97464597\n",
      "56473202\n",
      "382810104\n",
      "18198948\n",
      "22583725\n",
      "287183523\n",
      "2153036188\n",
      "76987535\n",
      "104863726\n",
      "9554732\n",
      "16513349\n",
      "18580155\n",
      "128750531\n",
      "103348497\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/react+following.json\") as file:\n",
    "    node_relations = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for key, values in node_relations.items():\n",
    "    for id in values[\"rumours\"]: G.add_edge(id,key)\n",
    "    for id in values[\"non_rumours\"]: G.add_edge(id,key)\n",
    "    for id in values[\"bridges\"]: G.add_edge(id,key)\n",
    "    for id in values[\"uncategorized\"]: G.add_edge(id,key)\n",
    "\n",
    "# Node attributes\n",
    "attributes = {}\n",
    "for community, ids in communities.items(): \n",
    "    for id in ids: attributes[id] = community\n",
    "\n",
    "nx.set_node_attributes(G,attributes,\"at\")\n",
    "for x,y in G.nodes(data=True):\n",
    "    try: filt = y[\"at\"]\n",
    "    except: print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3']\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_edge(\"1\",\"2\")\n",
    "G.add_edge(\"2\",\"3\")\n",
    "G.add_edge(\"1\",\"3\")\n",
    "\n",
    "attributes = {\n",
    "    \"1\":\"rumours\",\n",
    "    \"2\":\"rumours\",\n",
    "    \"3\":\"non_rumours\",\n",
    "    \"4\":\"non_rumours\"\n",
    "}\n",
    "nx.set_node_attributes(G, attributes,\"at\")\n",
    "nodes = [x for x,y in G.nodes(data=True) if y['at']==\"non_rumours\"]\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Centrality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In degree analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree = nx.in_degree_centrality(G)\n",
    "rum = {}\n",
    "non_rum = {}\n",
    "bridges = {}\n",
    "\n",
    "for id in list(in_degree):\n",
    "    if id in communities[\"rumours\"] : rum[id]=in_degree[id]\n",
    "    elif id in communities[\"non_rumours\"] : non_rum[id]=in_degree[id]\n",
    "    elif id in communities[\"bridges\"] : bridges[id]=in_degree[id]\n",
    "\n",
    "# Sort each list \n",
    "rum = dict(sorted(rum.items(), key=lambda item: item[1],reverse=True))\n",
    "non_rum = dict(sorted(non_rum.items(), key=lambda item: item[1],reverse=True))\n",
    "bridges = dict(sorted(bridges.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "in_degree = {\n",
    "    \"rumours\": rum,\n",
    "    \"non_rum\": non_rum,\n",
    "    \"bridges\": bridges\n",
    "}\n",
    "\n",
    "head.writeToJSON(head.makePath([centrality_path,\"degree\"]),\"in_degree\",in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inDegree = ch.indegree_centrality(rf_G)\n",
    "head.writeToJSON(head.makePath([centrality_path,\"follow+react\"]),\"inDegree\",inDegree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out degree analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree = nx.out_degree_centrality(G)\n",
    "rum = {}\n",
    "non_rum = {}\n",
    "bridges = {}\n",
    "\n",
    "for id in list(in_degree):\n",
    "    if id in communities[\"rumours\"] : rum[id]=out_degree[id]\n",
    "    elif id in communities[\"non_rumours\"] : non_rum[id]=out_degree[id]\n",
    "    elif id in communities[\"bridges\"] : bridges[id]=out_degree[id]\n",
    "\n",
    "# Sort each list \n",
    "rum = dict(sorted(rum.items(), key=lambda item: item[1],reverse=True))\n",
    "non_rum = dict(sorted(non_rum.items(), key=lambda item: item[1],reverse=True))\n",
    "bridges = dict(sorted(bridges.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "out_degree = {\n",
    "    \"rumours\": rum,\n",
    "    \"non_rum\": non_rum,\n",
    "    \"bridges\": bridges\n",
    "}\n",
    "\n",
    "head.writeToJSON(head.makePath([centrality_path,\"degree\"]),\"out_degree_2\",out_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweeness centrality analysis\n",
    "\n",
    "The betweeness centrality analysis is based upon non-directed graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cen = nx.betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None)\n",
    "rum = {}\n",
    "non_rum = {}\n",
    "bridges = {}\n",
    "\n",
    "for id in list(bet_cen):\n",
    "    if id in communities[\"rumours\"] : rum[id]=bet_cen[id]\n",
    "    elif id in communities[\"non_rumours\"] : non_rum[id]=bet_cen[id]\n",
    "    elif id in communities[\"bridges\"] : bridges[id]=bet_cen[id]\n",
    "\n",
    "# Sort each list \n",
    "rum = dict(sorted(rum.items(), key=lambda item: item[1],reverse=True))\n",
    "non_rum = dict(sorted(non_rum.items(), key=lambda item: item[1],reverse=True))\n",
    "bridges = dict(sorted(bridges.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "new_between = {\n",
    "    \"rumours\": rum,\n",
    "    \"non_rumours\": non_rum,\n",
    "    \"bridges\": bridges\n",
    "}\n",
    "\n",
    "head.writeToJSON(head.makePath([centrality_path,\"betweeness\"]),\"directed_betweenness\",new_between)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closeness Analysis\n",
    "\n",
    "Type 1 bridges within rumour community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by_v2.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "rum_G = nx.DiGraph()\n",
    "\n",
    "rum_G.add_nodes_from(communities[\"rumours\"])\n",
    "rumourEdges = []\n",
    "rumourNodes = communities[\"rumours\"]\n",
    "\n",
    "non_rumourNodes = communities[\"non_rumours\"]\n",
    "\n",
    "rum_G.add_nodes_from(communities[\"bridges\"])\n",
    "bridgeEdges = []\n",
    "bridgeNodes = communities[\"bridges\"]\n",
    "\n",
    "for id in followed_by:\n",
    "    if id in non_rumourNodes: continue\n",
    "\n",
    "    user = followed_by[id]\n",
    "\n",
    "    for follower in user[\"rumours\"]: \n",
    "        rumourEdges.append((follower,id))\n",
    "        rum_G.add_edge(follower,id)\n",
    "    \n",
    "    for follower in user[\"bridges\"]: \n",
    "        bridgeEdges.append((follower,id))\n",
    "        rum_G.add_edge(follower,id)\n",
    "\n",
    "isolates = list(nx.isolates(rum_G))\n",
    "rum_G.remove_edges_from(isolates)\n",
    "\n",
    "isolates = set(isolates)\n",
    "rumourNodes = set(rumourNodes).difference(isolates)\n",
    "bridgeNodes = set(bridgeNodes).difference(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rumour_closeness = nx.closeness_centrality(rum_G)\n",
    "rum = {}\n",
    "bridges = {}\n",
    "\n",
    "for id in list(rumour_closeness):\n",
    "    if id in communities[\"rumours\"] : rum[id]=rumour_closeness[id]\n",
    "    elif id in communities[\"bridges\"] : bridges[id]=rumour_closeness[id]\n",
    "\n",
    "# Sort each list \n",
    "rum = dict(sorted(rum.items(), key=lambda item: item[1],reverse=True))\n",
    "bridges = dict(sorted(bridges.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "rumour_closeness = {\n",
    "    \"rumours\": rum,\n",
    "    \"bridges\": bridges\n",
    "}\n",
    "\n",
    "head.writeToJSON(centrality_path,\"rumour_closeness_2\",rumour_closeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 1 bridges within nonrumour community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by_v2.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "non_rum_G = nx.DiGraph()\n",
    "\n",
    "rumourNodes = communities[\"rumours\"]\n",
    "\n",
    "non_rum_G.add_nodes_from(communities[\"non_rumours\"])\n",
    "non_rumourEdges = []\n",
    "non_rumourNodes = communities[\"non_rumours\"]\n",
    "\n",
    "non_rum_G.add_nodes_from(communities[\"bridges\"])\n",
    "bridgeEdges = []\n",
    "bridgeNodes = communities[\"bridges\"]\n",
    "\n",
    "for id in followed_by:\n",
    "    if id in rumourNodes: continue\n",
    "\n",
    "    user = followed_by[id]\n",
    "\n",
    "    for follower in user[\"non_rumours\"]: \n",
    "        non_rumourEdges.append((follower,id))\n",
    "        non_rum_G.add_edge(follower,id)\n",
    "    \n",
    "    for follower in user[\"bridges\"]: \n",
    "        bridgeEdges.append((follower,id))\n",
    "        non_rum_G.add_edge(follower,id)\n",
    "\n",
    "isolates = list(nx.isolates(non_rum_G))\n",
    "non_rum_G.remove_edges_from(isolates)\n",
    "\n",
    "isolates = set(isolates)\n",
    "rumourNodes = set(rumourNodes).difference(isolates)\n",
    "non_rumourNodes = set(non_rumourNodes).difference(isolates)\n",
    "bridgeNodes = set(bridgeNodes).difference(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rumour_closeness = nx.closeness_centrality(non_rum_G)\n",
    "non_rum = {}\n",
    "bridges = {}\n",
    "\n",
    "for id in list(non_rumour_closeness):\n",
    "    if id in communities[\"non_rumours\"] : non_rum[id]=non_rumour_closeness[id]\n",
    "    elif id in communities[\"bridges\"] : bridges[id]=non_rumour_closeness[id]\n",
    "\n",
    "# Sort each list \n",
    "non_rum = dict(sorted(non_rum.items(), key=lambda item: item[1],reverse=True))\n",
    "bridges = dict(sorted(bridges.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "non_rumour_closeness = {\n",
    "    \"non_rumours\": non_rum,\n",
    "    \"bridges\": bridges\n",
    "}\n",
    "\n",
    "head.writeToJSON(head.makePath([centrality_path,\"closeness\"]),\"non_rumour_closeness\",non_rumour_closeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectiveness within rumour community  \n",
    "Labels are given to nodes with more than 2 in-going edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "# with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/degree/in_degree.json\") as file:\n",
    "#     in_degree = json.load(file)\n",
    "\n",
    "rum_community = communities[\"rumours\"]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(rum_community)\n",
    "\n",
    "for id in rum_community:\n",
    "    try : followers = (followed_by[id])[\"rumours\"]\n",
    "    except: continue\n",
    "    \n",
    "    for f in followers:\n",
    "        G.add_edge(f,id)\n",
    "\n",
    "labels = {}\n",
    "for id in G:\n",
    "    if (G.in_degree[id] > 2) : labels[id] = id+\": \"+str(G.in_degree[id])\n",
    "\n",
    "# pos = nx.spring_layout(G)\n",
    "pos = nx.spring_layout(G, k=0.8)\n",
    "# , iterations=20\n",
    "nx.draw(G,pos,node_size=40)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=labels.keys(), node_size=60)\n",
    "nx.draw_networkx_labels(G,pos,labels,font_size=13,font_color='r')\n",
    "x_values, y_values = zip(*pos.values())\n",
    "x_max = max(x_values)\n",
    "x_min = min(x_values)\n",
    "x_margin = (x_max - x_min) * 0.25\n",
    "plt.xlim(x_min - x_margin, x_max + x_margin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectivity within non-rumour community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "# with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/degree/in_degree.json\") as file:\n",
    "#     in_degree = json.load(file)\n",
    "\n",
    "nonrum_community = communities[\"non_rumours\"]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nonrum_community)\n",
    "\n",
    "for id in nonrum_community:\n",
    "    try : followers = (followed_by[id])[\"non_rumours\"]\n",
    "    except: continue\n",
    "    \n",
    "    for f in followers:\n",
    "        G.add_edge(f,id)\n",
    "\n",
    "labels = {}\n",
    "for id in G:\n",
    "    if (G.in_degree[id] > 0) : labels[id] = id+\": \"+str(G.in_degree[id])\n",
    "\n",
    "# pos = nx.spring_layout(G)\n",
    "pos = nx.spring_layout(G, k=0.8)\n",
    "# , iterations=20\n",
    "nx.draw(G,pos,node_size=40,node_color=\"green\")\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=labels.keys(), node_size=60)\n",
    "nx.draw_networkx_labels(G,pos,labels,font_size=13,font_color='r')\n",
    "x_values, y_values = zip(*pos.values())\n",
    "x_max = max(x_values)\n",
    "x_min = min(x_values)\n",
    "x_margin = (x_max - x_min) * 0.25\n",
    "plt.xlim(x_min - x_margin, x_max + x_margin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = set(isolates)\n",
    "rumourNodes = list(set(rumourNodes).difference(isolates))\n",
    "non_rumourNodes = list(set(non_rumourNodes).difference(isolates))\n",
    "bridgeNodes = list(set(bridgeNodes).difference(isolates))\n",
    "\n",
    "# pos = nx.spring_layout(G, k=0.15, iterations=20)\n",
    "pos = nx.random_layout(G)\n",
    "node_size = 30\n",
    "\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=rumourNodes, node_size=node_size, node_color=\"tab:red\")\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=non_rumourNodes, node_size=node_size, node_color=\"tab:green\")\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=bridgeNodes, node_size=node_size, node_color=\"tab:blue\")\n",
    "\n",
    "# nx.draw_networkx_edges(\n",
    "#             G,\n",
    "#             pos,\n",
    "#             edgelist=G.out_edges(rumourNodes),\n",
    "#             edge_color=\"tab:red\"\n",
    "#         )\n",
    "# nx.draw_networkx_edges(\n",
    "#             G,\n",
    "#             pos,\n",
    "#             edgelist=G.out_edges(non_rumourNodes),\n",
    "#             edge_color=\"tab:green\"\n",
    "#         )\n",
    "# nx.draw_networkx_edges(\n",
    "#             G,\n",
    "#             pos,\n",
    "#             edgelist=G.in_edges(bridgeNodes),\n",
    "#             edge_color=\"tab:blue\"\n",
    "#         )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.bipartite.gnmk_random_graph(3, 5, 10, seed=123)\n",
    "top = nx.bipartite.sets(G)[0]\n",
    "pos = nx.bipartite_layout(G, top)\n",
    "nx.draw(G,pos)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
