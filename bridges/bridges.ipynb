{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset')\n",
    "import header as head\n",
    "import bridge_header as bh\n",
    "\n",
    "bridges_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges\"\n",
    "follow_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow\"\n",
    "react_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/react\"\n",
    "FR_path = \"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow+react\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Nodes that have followers from both communities. \n",
    "2. Nodes that follows other communites but only has follower from one commmunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**code preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained who followed by whom relationship\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as f:\n",
    "    follows = json.load(f)\n",
    "\n",
    "who_followed_by_whom = {}\n",
    "# Find who followed by whom\n",
    "for user in follows:\n",
    "    who_followed_by_whom[user] = []\n",
    "    followed_by = who_followed_by_whom[user]\n",
    "\n",
    "    for f in follows:\n",
    "        if user in follows[f]: followed_by.append(f)\n",
    "\n",
    "# head.writeToJSON(head.getRoot(),\"who_followed_by_whom\",who_followed_by_whom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all followers from both communities per user \n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/communities.json\") as f:\n",
    "    communities = json.load(f)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as f:\n",
    "    follows = json.load(f)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who_followed_by_whom.json\") as f:\n",
    "    followed_by = json.load(f)\n",
    "\n",
    "rumours_set = communities[\"rumours\"]\n",
    "non_rumours_set = communities[\"non_rumours\"]\n",
    "uncategorized_set = communities[\"uncategorized\"]\n",
    "\n",
    "bridges = {}\n",
    "ids = []\n",
    "for c in communities.keys():\n",
    "    ids.extend(communities[c])\n",
    "\n",
    "\n",
    "for id in ids:\n",
    "    try:\n",
    "        followers = followed_by[id]\n",
    "    except: \n",
    "        continue\n",
    "    \n",
    "    bridges[id] = {\n",
    "        \"rumours\" : [],\n",
    "        \"non_rumours\" : [],\n",
    "        \"uncategorized\" : []\n",
    "    }\n",
    "    node = bridges[id]\n",
    "\n",
    "    for followee in followers:\n",
    "        if followee in rumours_set: node[\"rumours\"].append(followee)\n",
    "        elif followee in non_rumours_set: node[\"non_rumours\"].append(followee)\n",
    "        elif followee in uncategorized_set: node[\"uncategorized\"].append(followee)\n",
    "    \n",
    "    # uncomment the following if statement to obtain \"user_followed_by_unfiltered\" file\n",
    "    if (len(node[\"rumours\"])==0 and len(node[\"non_rumours\"])==0\n",
    "        and len(node[\"uncategorized\"])==0): bridges.pop(id)\n",
    "\n",
    "head.writeToJSON(bridges_path,\"user_followed_by\",bridges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test whether type 3 bridges affect the identification of type 1 bridge. \n",
    "\n",
    "Result: type 3 bridges does not affect the amount of type 1 bridges being identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/bridges.json\") as file:\n",
    "    b1 = json.load(file)\n",
    "    b1 = b1.keys()\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/bridges_v2.json\") as file:\n",
    "    b2 = json.load(file)\n",
    "    b2 = b2.keys()\n",
    "\n",
    "print(b1==b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update user_followed_by with additional information about bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/bridges.json\") as file:\n",
    "    bridges = json.load(file)\n",
    "    bridge_ids = bridges.keys()\n",
    "\n",
    "new_followed_by = {}\n",
    "\n",
    "for f in followed_by:\n",
    "    user = followed_by[f]\n",
    "    new_followed_by[f] = {\n",
    "        \"rumours\":[],\n",
    "        \"non_rumours\":[],\n",
    "        \"uncategorized\":[],\n",
    "        \"bridges\":[]\n",
    "    }\n",
    "\n",
    "    for id in user[\"rumours\"]:\n",
    "        if id in bridge_ids : (new_followed_by[f])[\"bridges\"].append(id)\n",
    "        else : (new_followed_by[f])[\"rumours\"].append(id)\n",
    "    \n",
    "    for id in user[\"non_rumours\"]:\n",
    "        if id in bridge_ids : (new_followed_by[f])[\"bridges\"].append(id)\n",
    "        else : (new_followed_by[f])[\"non_rumours\"].append(id)\n",
    "\n",
    "    for id in user[\"uncategorized\"]:\n",
    "        if id in bridge_ids : (new_followed_by[f])[\"bridges\"].append(id)\n",
    "        else : (new_followed_by[f])[\"uncategorized\"].append(id)\n",
    "\n",
    "head.writeToJSON(bridges_path,\"user_followed_by\",new_followed_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 1 Bridge Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get type 1 bridges\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([follow_path,\"type 1\"]),\"type1\",bh.getType1(followed_by))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get who type 1 bridges follow\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow/type 1/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as file:\n",
    "    follows = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([follow_path,\"type 1\"]),\"follow_whom\",bh.getFollows(type1,follows,communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which community does each type 1 bridge originate from\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow/type 1/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/communities.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([follow_path,\"type 1\"]),\"originate_from\",bh.originateFrom(type1,communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of tweets does each type 1 bridge tweets\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow/type 1/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/annotations/tweets_type_by_userId.json\") as file:\n",
    "    tweets_type = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([follow_path,\"type 1\"]),\"tweets_type\",bh.tweets_type(type1,tweets_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow+React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get who type 1 bridges follow\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow+react/type 1/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/FR_to_whom.json\") as file:\n",
    "    RF_relations = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow+react/communities.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([FR_path,\"type 1\"]),\"FR_whom\",bh.getFollows(type1,RF_relations,communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which community does each type 1 bridge originate from\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow+react/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/communities.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([FR_path,\"type 1\"]),\"originate_from\",bh.originateFrom(type1,communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of tweets does each type 1 bridge tweets\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow+react/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/annotations/tweets_type_by_userId.json\") as file:\n",
    "    tweets_type = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([FR_path,\"type 1\"]),\"tweets_type\",bh.tweets_type(type1,tweets_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining centrality information regarding type 1 bridges' followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/type 1/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/betweeness/directed_betweenness.json\") as file:\n",
    "    betweeness = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/closeness/rumour_closeness.json\") as file:\n",
    "    rum_closeness = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/closeness/non_rumour_closeness.json\") as file:\n",
    "    nonrum_closeness = json.load(file)\n",
    "\n",
    "type1_centrality = {}\n",
    "\n",
    "for id in type1:\n",
    "    bridge = type1[id]\n",
    "    type1_centrality[id] = {\n",
    "        \"rum_count\" : len((bridge[\"followed_by\"])[\"rumours\"]),\n",
    "        \"nonrum_count\" : len((bridge[\"followed_by\"])[\"non_rumours\"]),\n",
    "        \"rumours\" : {},\n",
    "        \"non_rumours\" : {},\n",
    "    }\n",
    "\n",
    "    rum_followers = (type1_centrality[id])[\"rumours\"]\n",
    "    nonrum_followers = (type1_centrality[id])[\"non_rumours\"]\n",
    "\n",
    "    for user in (bridge[\"followed_by\"])[\"rumours\"]:\n",
    "        betw = (betweeness[\"rumours\"])[user]\n",
    "        close = (rum_closeness[\"rumours\"])[user]\n",
    "        if betw > 0 or close > 0:\n",
    "            rum_followers[user] = {\n",
    "                \"betweeness\":(betweeness[\"rumours\"])[user],\n",
    "                \"closeness\":(rum_closeness[\"rumours\"])[user]\n",
    "            }\n",
    "    \n",
    "    for user in (bridge[\"followed_by\"])[\"non_rumours\"]:\n",
    "        betw = (betweeness[\"non_rumours\"])[user]\n",
    "        close = (nonrum_closeness[\"non_rumours\"])[user]\n",
    "        if betw > 0 or close > 0:\n",
    "            nonrum_followers[user] = {\n",
    "                \"betweeness\":(betweeness[\"non_rumours\"])[user],\n",
    "                \"closeness\":(nonrum_closeness[\"non_rumours\"])[user]\n",
    "            }\n",
    "\n",
    "head.writeToJSON(head.makePath([bridges_path,\"type 1\"]),\"centrality_2\",type1_centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow+React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow+react/type1.json\") as file:\n",
    "    type1 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/follow+react/betweeness/betweeness.json\") as file:\n",
    "    betweeness = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/follow+react/closeness/nonrumours.json\") as file:\n",
    "    nonrum_closeness = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/follow+react/closeness/rumours.json\") as file:\n",
    "    rum_closeness = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/follow+react/closeness/nonrumours+uncategorized.json\") as file:\n",
    "    uncat_nonrum_closeness = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/centrality/follow+react/closeness/rumours+uncategorized.json\") as file:\n",
    "    uncat_rum_closeness = json.load(file)\n",
    "\n",
    "centralities = bh.get_centralities(type1,betweeness,nonrum_closeness,rum_closeness,uncat_nonrum_closeness,uncat_rum_closeness)\n",
    "head.writeToJSON(head.makePath([bridges_path,\"follow+react\"]),\"centralities\",centralities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 2 Bridge Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get type 2 bridges\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as file:\n",
    "    follows = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([follow_path,\"type 2\"]),\"type2_2\",bh.getType2(followed_by,follows,communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow+React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get type 2 bridges\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/react+following.json\") as file:\n",
    "    FR_relations = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/who-follows-whom.json\") as file:\n",
    "    follows = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow+react/communities.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([FR_path,\"type 2\"]),\"type2\",bh.getType2(FR_relations,follows,communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 3 Bridge Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get type 3 bridges\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow/user_followed_by.json\") as file:\n",
    "    followed_by = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow/with_bridges.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([follow_path,\"type 3\"]),\"type 3\",bh.getType3(followed_by,communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow+React"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get type 3 bridges\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/react+following.json\") as file:\n",
    "    FR_relations = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow+react/communities.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([FR_path,\"type 3\"]),\"type 3\",bh.getType3(FR_relations,communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get who type 3 bridges follow\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/bridges/follow+react/type 3/type 3.json\") as file:\n",
    "    type3 = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/FR_to_whom.json\") as file:\n",
    "    RF_relations = json.load(file)\n",
    "\n",
    "with open(\"/Users/yu-hung/Downloads/pheme-rumour-scheme-dataset/community_detection/follow+react/communities.json\") as file:\n",
    "    communities = json.load(file)\n",
    "\n",
    "head.writeToJSON(head.makePath([FR_path,\"type 3\"]),\"FR_whom\",bh.getFollows(type3,RF_relations,communities))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
